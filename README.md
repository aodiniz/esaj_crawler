
# e-SAJ Crawler

The goal of this project is to obtain general data from Brazilian Justice Courts that employ the e-SAJ system.  
To accomplish the data extraction, it is applied a web-crawler developed using Python and Selenium, alongside other auxiliary libraries.

## How to run

### Environment setup

#### Firefox driver

Download and install the [latest Mozilla Firefox driver](https://github.com/mozilla/geckodriver/releases) and make sure it's included on your path, as described on the [Selenium Python documentation page](https://selenium-python.readthedocs.io/installation.html#drivers).

If a warning is displayed on run-time, you may choose (or not) to change the driver version accordingly.

### Cloning the repository

On Terminal / Console, run `git clone https://github.com/aodiniz/esaj_crawler.git`

### Python dependencies setup



### Extracting data

## How to explore the data

### Integration with Databricks

For easy experimentation on the extracted data, use the following notebooks:

* [e-SAJ Raw Data Loading (SÃ£o Paulo Justice Court)](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4344861173232069/3708033308179043/6869627049114758/latest.html)
